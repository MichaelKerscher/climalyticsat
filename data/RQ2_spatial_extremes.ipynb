{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593e5aaf",
   "metadata": {},
   "source": [
    "# Spatial Patterns of Extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e348d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ad09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.functions import sum as _sum\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30aae6b",
   "metadata": {},
   "source": [
    "## Stop session if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57919677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665dec5a",
   "metadata": {},
   "source": [
    "## Start Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').appName('Climalyticsat').config('spark.driver.memory', '8g').config('spark.executor.memory', '8g').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb3672",
   "metadata": {},
   "source": [
    "## Load data and write out as Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196e0b3",
   "metadata": {},
   "source": [
    "### Load all station's climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = spark.read.csv('climate_all_stations.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88634e",
   "metadata": {},
   "source": [
    "### Extract a “year” column for efficient time‐based pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn string into a proper date, then pull out the year\n",
    "climate_data = (\n",
    "    climate_data\n",
    "      .withColumn('date',   to_date('date', 'yyyy-MM'))\n",
    "      .withColumn('year',   year('date'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d5a58",
   "metadata": {},
   "source": [
    "### Load and join stations metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = (\n",
    "    spark.read\n",
    "         .csv('stations_metadata.csv', header=True, inferSchema=True)\n",
    "         .withColumnRenamed('id', 'station_id')\n",
    "         .withColumnRenamed('Höhe [m]', 'elevation')\n",
    "         .select('station_id', 'elevation')\n",
    ")\n",
    "\n",
    "climate = climate_data.join(stations, on='station_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d5a58",
   "metadata": {},
   "source": [
    "#### Bucket elevation into (250m) bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = climate.withColumn(\n",
    "    'elevation_band',\n",
    "    (floor(climate.elevation / 250) * 250).cast('int')  # 0–249m → 0, 250–499m → 250, etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2611cab",
   "metadata": {},
   "source": [
    "### Write out as Parquet, partitioned by year & elevation_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate.write.partitionBy('year', 'elevation_band').parquet('extremes_parquet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3ce49",
   "metadata": {},
   "source": [
    "## RQ2 - Spatial Patterns of Extremes\n",
    "Which geographic zones (valleys, plateaus, alpine corridors) show the largest shifts in “hot days” (≥ 30 °C) and “frost days” (≤ 0 °C) since 1970?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a3076",
   "metadata": {},
   "source": [
    "### Load Parquet (qear, elevation_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a799207",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = spark.read.parquet('extremes_parquet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624eb16",
   "metadata": {},
   "source": [
    "### Add geographical zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed columns\n",
    "# tage_tropen,Tropentage,\"Zahl der Tropentage,  Tagesmaximum der Lufttemperatur in 2 m Höhe >=30.0°C\",d\n",
    "# tage_frost,Frosttage,\"Zahl der Frosttage, 24-Stunden-Minimalwert der Lufttemperatur in 2m Höhe < 0.0 °C\",d\n",
    "\n",
    "climate = climate.withColumn(\n",
    "    'zone',\n",
    "    when(col('elevation') <= 700,      'valley')\n",
    "   .when((col('elevation') > 700) & (col('elevation') <= 1500), 'plateau')\n",
    "   .otherwise('alpine')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6c57d2",
   "metadata": {},
   "source": [
    "### Compute the “shift” since 1970"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23bd440",
   "metadata": {},
   "source": [
    "#### End-minus-start difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) total per station×year\n",
    "zone_year_station = (\n",
    "    climate\n",
    "      .groupBy('zone','station_id','year')\n",
    "      .agg(\n",
    "        _sum('tage_tropen').alias('hot_days'),\n",
    "        _sum('tage_frost').alias('frost_days')\n",
    "      )\n",
    ")\n",
    "\n",
    "# 2) average per zone×year\n",
    "zone_year = (\n",
    "    zone_year_station\n",
    "      .groupBy('zone','year')\n",
    "      .agg(\n",
    "        avg('hot_days' ).alias('hot_days'),\n",
    "        avg('frost_days').alias('frost_days')\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547988e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_decade = (zone_year\n",
    "    .filter(col('year').between(1970,1979))\n",
    "    .groupBy('zone')\n",
    "    .agg(avg('hot_days').alias('hot_70s'),\n",
    "         avg('frost_days').alias('frost_70s'))\n",
    ")\n",
    "\n",
    "last_decade = (zone_year\n",
    "    .filter(col('year').between(2014,2023))\n",
    "    .groupBy('zone')\n",
    "    .agg(avg('hot_days').alias('hot_10s'),\n",
    "         avg('frost_days').alias('frost_10s'))\n",
    ")\n",
    "\n",
    "shift = (first_decade\n",
    "    .join(last_decade, 'zone')\n",
    "    .withColumn('hot_shift',   col('hot_10s')   - col('hot_70s'))\n",
    "    .withColumn('frost_shift', col('frost_10s') - col('frost_70s'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the per-zone, per-decade averages\n",
    "first_decade.show(truncate=False)\n",
    "last_decade.show(truncate=False)\n",
    "\n",
    "# print the computed shifts\n",
    "shift.select('zone','hot_70s','hot_10s','hot_shift',\n",
    "             'frost_70s','frost_10s','frost_shift') \\\n",
    "     .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c15ab",
   "metadata": {},
   "source": [
    "#### Visualize with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shift_pd = shift.toPandas()\n",
    "\n",
    "zones      = shift_pd['zone']\n",
    "hot_shift  = shift_pd['hot_shift']\n",
    "frost_shift= shift_pd['frost_shift']\n",
    "x = range(len(zones))\n",
    "\n",
    "plt.figure()\n",
    "plt.bar([i - 0.2 for i in x], hot_shift,   width=0.4, label='Hot Days Shift')\n",
    "plt.bar([i + 0.2 for i in x], frost_shift, width=0.4, label='Frost Days Shift')\n",
    "plt.xticks(x, zones)\n",
    "plt.xlabel('Zone')\n",
    "plt.ylabel('Change in Average Number of Days')\n",
    "plt.title('Shift in Hot (≥30 °C) & Frost (≤0 °C) Days Since 1970 by Zone')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_counts = (\n",
    "    climate\n",
    "      .select('station_id', 'zone')\n",
    "      .distinct()\n",
    "      .groupBy('zone')\n",
    "      .agg(countDistinct('station_id').alias('num_stations'))\n",
    "      .orderBy('zone')\n",
    ")\n",
    "\n",
    "# 3) Bring to Pandas & plot\n",
    "station_counts_pd = station_counts.toPandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "zones  = station_counts_pd['zone']\n",
    "counts = station_counts_pd['num_stations']\n",
    "x      = range(len(zones))\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x, counts)\n",
    "plt.xticks(x, zones)\n",
    "plt.xlabel('Zone')\n",
    "plt.ylabel('Number of Stations')\n",
    "plt.title('Number of Weather Stations per Zone')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5161b4",
   "metadata": {},
   "source": [
    "### Build your per‐zone time series (mean hot/frost days per station per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717007b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_year = (\n",
    "    climate\n",
    "      # only keep years up to 2023, since for 2024 no or very little data is available\n",
    "      .filter(col('year') <= 2023)\n",
    "      .groupBy('zone','station_id','year')\n",
    "      .agg(\n",
    "        _sum('tage_tropen').alias('hot_days'),\n",
    "        _sum('tage_frost').alias('frost_days')\n",
    "      )\n",
    "      .groupBy('zone','year')\n",
    "      .agg(\n",
    "        avg('hot_days').alias('hot_days'),\n",
    "        avg('frost_days').alias('frost_days')\n",
    "      )\n",
    "      .orderBy('zone','year')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e8fe56",
   "metadata": {},
   "source": [
    "#### Plot the full time-series by zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03007bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['hot_days','frost_days']:\n",
    "    plt.figure()\n",
    "    for zone, grp in zone_year.toPandas().groupby('zone'):\n",
    "        plt.plot(grp['year'], grp[metric], marker='o', label=zone)\n",
    "    plt.title(f\"Yearly avg. {metric.replace('_',' ').title()} by Zone\")\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(f\"Avg. {metric.replace('_',' ').title()}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942dfb80",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64332052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit one regression per zone\n",
    "slopes = []\n",
    "for zone_name in ['valley','plateau','alpine']:\n",
    "    sdf = zone_year.filter(col('zone') == zone_name)\n",
    "    \n",
    "    # assemble the feature vector (just year)\n",
    "    va = VectorAssembler(inputCols=['year'], outputCol='features')\n",
    "    sdf = va.transform(sdf)\n",
    "\n",
    "    # hot‐day trend\n",
    "    lr_hot = LinearRegression(featuresCol='features',\n",
    "                              labelCol='hot_days')\n",
    "    m_hot  = lr_hot.fit(sdf)\n",
    "    # frost‐day trend\n",
    "    lr_frost = LinearRegression(featuresCol='features',\n",
    "                                labelCol='frost_days')\n",
    "    m_frost  = lr_frost.fit(sdf)\n",
    "\n",
    "    # extract and cast to plain Python floats\n",
    "    slopes.append((\n",
    "      zone_name,\n",
    "      float(m_hot.coefficients[0]),\n",
    "      float(m_frost.coefficients[0])\n",
    "    ))\n",
    "\n",
    "    s_hot = m_hot.summary\n",
    "    print(f\"{zone_name} — hot days:\")\n",
    "    print(f\"  slope = {m_hot.coefficients[0]:.3f} days/yr, R² = {s_hot.r2:.3f}, p = {s_hot.pValues[1]:.3e}\")\n",
    "\n",
    "    s_f = m_frost.summary\n",
    "    print(f\"{zone_name} — frost days:\")\n",
    "    print(f\"  slope = {m_frost.coefficients[0]:.3f} days/yr, R² = {s_f.r2:.3f}, p = {s_f.pValues[1]:.3e}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "slopes_df = spark.createDataFrame(\n",
    "    slopes,\n",
    "    schema=['zone','slope_hot','slope_frost']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd24bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Plot with matplotlib\n",
    "pd = slopes_df.toPandas()\n",
    "x = range(len(pd))\n",
    "plt.figure()\n",
    "plt.bar([i-0.2 for i in x], pd['slope_hot'],   width=0.4, label='Hot days / yr')\n",
    "plt.bar([i+0.2 for i in x], pd['slope_frost'], width=0.4, label='Frost days / yr')\n",
    "plt.xticks(x, pd['zone'])\n",
    "plt.ylabel('Days per Year Change')\n",
    "plt.title('Linear Trend in Hot & Frost Days by Zone (1970–2023)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
